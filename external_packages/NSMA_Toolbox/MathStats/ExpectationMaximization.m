function [wtBest, muBest, sigmaBest] = ExpectationMaximization(x, nG, varargin)

% ExpectationMaximization -  Expectation Maximization Algorithm
%
% [wtBest, muBest, sigmaBest] = ExpectationMaximization(x, nG, varargin) 
%
% INPUTS:
%       x - nS x nD array of data
%       nG - number of gaussians to fit
%       varargin PARAMETERS:
%           maxSteps - default 100
%           nTries - default 10
%           epsLogLikelihood - default 1e-5;
%           debug - default 0;      
% OUTPUTS:
%       wtBest - nG x 1 array of weights
%       muBest - nG x nD array of centers (means of gaussians)
%       sigmaBest - nG x nD x nD array of covariance matrices
%
% INTERNALS:
%       z - probability that pt j was generated by gaussian i: nG x nS
%
% ALGORITHM:
%   Mixture model: f(x, psi) = sum_i wt_i * f_i(x, psi)
%                  f_i(x, psi) = (2 * wt * sigma^2) ^ D/2 * exp (-0.5 (x - mu_i)' Sigma_i (x - mu_i))
%   observed vars: x
%   unobserved vars: z - nG x nD array of probability w_j generated by G_i
%   E-step: z_ij = f_i(x_j, psi)
%   M-step: wt_i = sum_j z_ij / sum_i sum_j z_ij
%           mu_i = sum_j z_ij x_j / sum_j z_ij        
%           Sigma_i = sum_j z_ij (x_j - mu_i) (x_j - mu_i)' / sum_j z_ij
%   log Likelihood ~=~ sum_i sum_j z_ij (log wt_i - 0.5 log Sigma_i^2 + (x_j - mu_i)' Sigma_i (x_j - mu_i)))
%
% REFERENCE McLachlan and Krishnan (1997) The EM Algorithm and Extensions. John Wiley.
%
% ADR 1999, version L1.0, last modified '99 by ADR

% status UNDER CONSTRUCTION


StatusWarning('UNDER CONSTRUCTION', 'EM')
rand('state',0);

% Parameters and setup
minSteps = 1;
maxSteps = 100;
nTries = 1;
epsLogLikelihood = 1e-5;
eta = 1.0;

debug = 0;
stochastic = 1;
Extract_varargin;

[nS, nD] = size(x);

% Preset
wt = zeros(nG,1); 
mu = zeros(nG,nD); 
sigma = zeros(nG,nD,nD); 
wtBest = wt; 
muBest = mu; 
sigmaBest = sigma; 
newwt = wt;
newmu = mu;
newsigma = sigma;
logLikelihoodBest = -Inf;

for iTry = 1:nTries
   
   DisplayProgress(iTry, nTries, 'Title', 'EM');
   
   % set up vars for this case
   curLogLikelihood = -Inf;
   deltaLogLikelihood = Inf;
   z = zeros(nS, nG);

   wt = zeros(nG, 1);
   mu = zeros(nG, nD);
   sigma = zeros(nG, nD, nD);
   
   % generate initial guesses
   wt = repmat(1/nG, nG, 1);
   for iG = 1:nG
      mu(iG,:) = x(floor(rand * nS),:);
      sigma(iG,:,:) = eye(nD);
   end
   
   iStep = 1;
   while (iStep < minSteps) | (deltaLogLikelihood > epsLogLikelihood & iStep <= maxSteps)
      
      % increment step
      iStep = iStep + 1;
      
      %   E-step     
      for iG = 1:nG
         z(:,iG) = gauss(x, wt, mu, sigma, iG) + (1e-100);
      end
      znorm = sum(z,2);
      for iG = 1:nG
         z(:,iG) = z(:,iG) ./ znorm;
      end
      
      if stochastic
         z0 = zeros(nS,1);
         z1 = rand(nS,1);
         for iG = 1:nG
            z1 = z1 - z(:,iG);
            f = find(z1 <= 1e-100 & z0 == 0);
            z0(f) = iG;
         end
         z = zeros(size(z));
         for iG = 1:nG
            z(find(z0 == iG),iG) = 1;
         end
      end
      
      % if anybody has totally lost, reset it
      for iG = 1:nG
         if ~isreal(sigma(iG,:,:)) | sum(z(:,iG)) == 0
            disp(['Resetting cluster..']);
            mu(iG,:) = x(floor(rand * nS),:);
            sigma(iG,:,:) = eye(nD);
            wt(iG) = 1-sum(wt([1:(iG-1) (iG+1):end]));
         end
      end
      
      % M-step
      for iG = 1:nG
         if stochastic
            newwt(iG) = sum(z0 == iG)/nS;
            newmu(iG,:) = mean(x(z0 == iG,:));
            newsigma(iG,:,:) = cov(x(z0 == iG,:));
         else
            newwt(iG) = sum(z(:,iG))/nS;
            newmu(iG,:) = wmean(x,z(:,iG));
            newsigma(iG,:,:) = wcov(x,z(:,iG));
         end
         wt = wt + eta * (newwt - wt);
         mu = mu + eta * (newmu - mu);
         sigma = sigma + eta * (newsigma - sigma);
      end
      
      % calculate log likelihood
      lastLogLikelihood = curLogLikelihood; 
      curLogLikelihood = LogLikelihood(x, z, wt, mu, sigma);
      deltaLogLikelihood = curLogLikelihood - lastLogLikelihood;
      if debug
         fprintf(2, '%3d: %3d: log(L) = %10.5f, but best = %10.5f\n', iTry, iStep, curLogLikelihood, logLikelihoodBest);
      end
            
   end % main while
   
   if isreal(sigma) & curLogLikelihood < 0 & curLogLikelihood > logLikelihoodBest 
      wtBest = wt;
      muBest = mu;
      sigmaBest = sigma;
      logLikelihoodBest = curLogLikelihood;
   end
end % main for
DisplayProgress close



%==============================
% FUNCTIONS

function G = gauss(x, wt, mu, sigma, iG)
%   G = wt exp(-0.5 (x - mu)' sigma (x - mu)
[nS, nD] = size(x);
mu0 = repmat(mu(iG,:), nS, 1);
sigma0 = squeeze(sigma(iG,:,:));
G = 1/area(sigma0) * wt(iG) * exp(-0.5 * sum( (( (x - mu0)/sqrtm(sigma0) ).^2), 2));

function L = LogLikelihood(x, z, wt, mu, sigma) 
%   log Likelihood ~=~ sum_i sum_j z_ij (log wt_i - 0.5 log Sigma_i^2 + (x_j - mu_i)' Sigma_i (x_j - mu_i)))

[nS, nD] = size(x);
[nS, nG] = size(z);
L = 0;
for iG = 1:nG
   mu0 = repmat(mu(iG,:), nS, 1);
   sigma0 = squeeze(sigma(iG,:,:));
   L = L + sum(log(gauss(x, wt, mu, sigma, iG)));
end

function A = area(sigma)
[nD,nD] = size(sigma);
A = prod(sqrt(2 * pi) * sqrtm(sigma) * ones(nD,1));